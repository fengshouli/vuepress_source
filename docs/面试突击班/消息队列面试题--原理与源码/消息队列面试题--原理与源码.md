# 1、讲一讲Kafka的ISR机制

## **生产者发送确认（ACKS）**

生产者可以选择以下3 种不同的确认模式。

acks=0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka 。

acks=1 意味若首领（Leader）在收到消息并把它写入到分区数据文件（到内存而不是要到磁盘）时会返回确认或错误响应。

acks=all 意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到消息，才会返回确认或错误响应。

### 三种模式的性能差别

acks=0

在acks=0 模式下的运行速度是非常快的，因为这里不太需要数据到副本

不过这种**模式会丢失消息**：比如发送的对象无法被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。所以选择了这种模式， 一定会丢失一些消息（一些异常、极端的情况）。

acks=1

在这个模式下，如果发生正常的首领选举，生产者会在选举时收到一个异常，如果生产者能正确的处理这个错误，它会**重试**发送消息，最终消息会安全到达新的首领那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃。

acks=all

这是最保险的做法——生产者会一直重试直到消息被成功提交。不过这也是最慢的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。

## ISR的动态复制方案

站在消费者的来说，因为生产发送消息时的acks对于消费来说有很大的延迟性（如果是用acks=all的话），那么这种情况下消费者可能要很长时间才能消费消息，这点对于消费者来说可能不能容忍。

这里就是有一个ISR机制：ISR的动态复制方案。ISR，也即In-Sync Replica

配置参数：Broker的min.insync.replicas参数，这个参数只表示最小的同步的副本数

这个参数的控制下，每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。

每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，这样的数据它才能被Consumer所消费。

并不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的消息。分区首领知道每个消息会被复制到哪个副本上, 在消息还没有被写入所有同步副本之前, 是不会发送给消费者的，尝试获取这些消息的请求会得到空的响应而不是错误。所以这里针对消费者消费该如何做呢？

### 示例

设置acks=all，且副本数为3
极端情况1：
默认min.insync.replicas=1，极端情况下如果ISR中只有leader一个副本时满足min.insync.replicas=1这个条件，此时producer发送的数据只要leader同步成功就会返回响应，如果此时leader所在的broker crash了，就必定会丢失数据！这种情况不就和acks=1一样了！所以我们需要适当的加大min.insync.replicas的值。

极端情况2：
min.insync.replicas=3（等于副本数），这种情况下要一直保证ISR中有所有的副本，且producer发送数据要保证所有副本写入成功才能接收到响应！一旦有任何一个broker crash了，ISR里面最大就是2了，不满足min.insync.replicas=3，就不可能发送数据成功了！

根据这两个极端的情况可以看出min.insync.replicas的取值，是kafka系统可用性和数据可靠性的平衡！

减小 min.insync.replicas 的值，一定程度上增大了系统的可用性，允许kafka出现更多的副本broker crash并且服务正常运行；但是降低了数据可靠性，可能会丢数据（极端情况1）。
增大 min.insync.replicas 的值，一定程度上增大了数据的可靠性，允许一些broker crash掉，且不会丢失数据（只要再次选举的leader是从ISR中选举的就行）；但是降低了系统的可用性，会允许更少的broker crash（极端情况2）。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1713263133047/c1411034c5304adf86db410f8323bf94.png)

以上配置：min.insync.replicas=3

在第一步中，Leader A总共收到3条消息，但由于ISR中的Follower只同步了第1条消息（m1），故只有m1被Commit，也即只有m1可被Consumer消费（因为min.insync.replicas=3）。

当然如果说min.insync.replicas=2 的话，那么消费者就可以消费m1和m2的消息。

**上图中的蓝色的虚线就是HW（High Watermark），HW 是指在分区中，已经被所有追随者（Follower）副本复制的消息的位置。**

还有一个概念就是**LEO（Log End Offset）**

LEO 是指在分区中当前最新消息的位置。LEO 表示分区日志中的最后一条消息的偏移量。LEO 包括已经被写入但尚未被所有追随者副本复制的消息，以及正在等待被写入的消息。LEO 是一个动态的属性，它会随着新消息的写入而逐渐增加。

这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。每次改变ISR后，Leader都会将最新的ISR持久化。

## 总结

Kafka的复制机制既不是完全的同步复制，也不是单纯异步复制。（虽然Leader是Follower之间是异步复制的，不过有ACKS和min.insync.replicas 两种参数来控制），ISR机制则有效地权衡了数据可靠性和性能之间的关系。

同时，当Leader故障时，在ISR集合中的Follower才有资格被选举为新的Leader。

# 2、讲一讲零拷贝原理以及MQ的运用

### **什么是零拷贝?**

零拷贝(英语: Zero-copy) 技术是指计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省CPU周期和内存带宽。

➢零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率

➢零拷贝技术减少了用户进程地址空间和内核地址空间之间因为上:下文切换而带来的开销

可以看出没有说不需要拷贝，只是说减少冗余[不必要]的拷贝。

下面这些组件、框架中均使用了零拷贝技术：Kafka、Netty、Rocketmq、Nginx、Apache。

### **传统数据传送机制**

比如：读取文件，再用socket发送出去，实际经过四次copy。

伪码实现如下：

buffer = File.read()

Socket.send(buffer)

1、第一次：将磁盘文件，读取到操作系统内核缓冲区；

2、第二次：将内核缓冲区的数据，copy到应用程序的buffer；

3、第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)；

4、第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。

![](file:///C:\Users\lijin\AppData\Local\Temp\ksohtml22056\wps1.jpg)![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1713263133047/3e80c5ce25ee4ac1afb7b70e35c6bee8.png)

#### ***mmap内存映射***

硬盘上文件的位置和应用程序缓冲区(application buffers)进行映射（建立一种一一对应关系），由于mmap()将文件直接映射到用户空间，所以实际文件读取时根据这个映射关系，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝，不再有文件内容从硬盘拷贝到内核空间的一个缓冲区。

mmap内存映射将会经历：3次拷贝: 1次cpu copy，2次DMA copy；

![](file:///C:\Users\lijin\AppData\Local\Temp\ksohtml22056\wps2.jpg)![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1713263133047/5749d8bdf46d4a599e6daadc620029fb.png)

![](file:///C:\Users\lijin\AppData\Local\Temp\ksohtml22056\wps3.jpg)

#### ***sendfile***

linux 2.1支持的sendfile

当调用sendfile()时，DMA将磁盘数据复制到kernel buffer，然后将内核中的kernel buffer直接拷贝到socket buffer。在硬件支持的情况下，甚至数据都并不需要被真正复制到socket关联的缓冲区内。取而代之的是，只有记录数据位置和长度的描述符被加入到socket缓冲区中，DMA模块将数据直接从内核缓冲区传递给协议引擎，从而消除了遗留的最后一次复制。

一旦数据全都拷贝到socket buffer，sendfile()系统调用将会return、代表数据转化的完成。socket buffer里的数据就能在网络传输了。

sendfile会经历：3次拷贝，1次CPU copy ，2次DMA copy；硬件支持的情况下，则是2次拷贝，0次CPU copy， 2次DMA copy。

![](file:///C:\Users\lijin\AppData\Local\Temp\ksohtml22056\wps4.jpg)![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1713263133047/c0634f7f6ec040a08c81338dd5743a8b.png)

# 3、讲一讲RocketMQ中Netty框架的运用

见随堂笔记图

RocketMQ实现Netty的通讯模型：总结几句话--应对面试：
1、Netty框架--基于NIO 的事件驱动的 异步的框架

2、RocketMQ里面简化了客户端、服务端 Remoting类

3、使用requestCode  可以实现不同的功能，交给不同的处理器（Processer）

4、里面使用了一大堆的JUC的，阻塞唤醒模型（异步转同步调用）：发令枪，信号量：限流、。这些

5、以上 如果你以后要自己实现基于Netty 复杂一点的自定义的框架，就可以参考RocketMQ的remoting的写法
